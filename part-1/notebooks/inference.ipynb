{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Notebook for Soil Classification Part 1\n",
    "\n",
    "## **1. Imports and Setups**\n",
    "\n",
    "Setting up all the necessary libraries for our soil classification project.\n",
    "\n",
    "We're using \n",
    "- PyTorch for deep learning\n",
    "- Pandas for data handling\n",
    "- Matplotlib for visualizations.\n",
    "  \n",
    "The key libraries here are torchvision (for computer vision tasks) and PIL (for image processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Model Evaluation**\n",
    "\n",
    "Loading our best saved model and testing it on some validation images gives us\n",
    "a qualitative sense of how well it's performing. This visual inspection can\n",
    "reveal patterns in errors and help us understand the model's strengths and\n",
    "weaknesses.\n",
    "\n",
    "Green titles indicate correct predictions, red titles show mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Replace the final layer to match our number of classes\n",
    "num_classes = 4\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"../data/model.pth\"\n",
    "\n",
    "# Reload our trained model\n",
    "try:\n",
    "    # Attempt to load the model directly for CUDA\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "except RuntimeError as e:\n",
    "    # If CUDA is not available but model was saved with CUDA tensors\n",
    "    if 'Attempting to deserialize object on a CUDA device' in str(e):\n",
    "        print(\"CUDA not available. Loading model on CPU instead.\")\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11. Prepare `submission.csv`**\n",
    "\n",
    "For the test set, we need a custom dataset class because the test images don't have labels and aren't organized in class folders. This custom class handles loading test images and keeping track of their filenames so we can create proper submissions.\n",
    "\n",
    "This is a common pattern when working with competition datasets where test data comes as a flat directory of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),           # Resize to model's expected input size\n",
    "    transforms.ToTensor(),                   # Convert to PyTorch Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize to match ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = os.listdir(test_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        img_path = os.path.join(self.test_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_name \n",
    "\n",
    "# Create test dataset and loader\n",
    "test_dir = \"../data/soil_classification-2025/test\"\n",
    "test_dataset = TestDataset(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Found {len(test_dataset)} test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is generating predictions for all test images and creating a submission file. We process images in batches for efficiency and convert the model's numeric predictions back to soil type names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Taken from Training Notebook\n",
    "idx_to_class = {0: 'Alluvial soil', 1: 'Black Soil', 2: 'Clay soil', 3: 'Red soil'}\n",
    "\n",
    "print(\"Generating predictions for test set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_names in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)           # Raw logits\n",
    "        _, preds = torch.max(outputs, 1) # Get class index with highest score\n",
    "\n",
    "        preds = preds.cpu().numpy()\n",
    "        \n",
    "        # Convert predictions to class names and store with image names\n",
    "        for img_name, pred_idx in zip(image_names, preds):\n",
    "            image_ids.append(img_name)\n",
    "            predicted_labels.append(idx_to_class[pred_idx])\n",
    "\n",
    "# Create DataFrame for submission\n",
    "submission_df = pd.DataFrame({\n",
    "    \"image_id\": image_ids,\n",
    "    \"soil_type\": predicted_labels\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Submission file created successfully!\")\n",
    "print(f\"Total predictions made: {len(submission_df)}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
